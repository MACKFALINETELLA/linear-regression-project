# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_6T0CvovwHniF10N000kLsuA4YW6NF5W
"""

# ðŸ“˜ Part 2: Load the uploaded Excel dataset
df = pd.read_excel('/content/road_accidents.xlsx')

# Display the first few rows and shape
print("âœ… Dataset Loaded Successfully!")
print("Shape of data:", df.shape)
print(df.head())

# ðŸ“˜ Part 3: Define target variable and feature columns

# The column we want to predict
target = 'severity'

# The columns (features) that affect severity
features = [
    'vehicle_speed', 'alcohol_level', 'weather', 'road_surface',
    'vehicle_age', 'time_of_day', 'num_vehicles', 'seatbelt_used', 'driver_age'
]

# Split columns by type for preprocessing
numeric_cols = ['vehicle_speed', 'alcohol_level', 'vehicle_age', 'num_vehicles', 'driver_age']
categorical_cols = ['weather', 'road_surface', 'time_of_day', 'seatbelt_used']

print("âœ… Target and feature columns defined successfully!")

# ðŸ“˜ Part 3: Define target variable and feature columns

# The column we want to predict
target = 'severity'

# The columns (features) that affect severity
features = [
    'vehicle_speed', 'alcohol_level', 'weather', 'road_surface',
    'vehicle_age', 'time_of_day', 'num_vehicles', 'seatbelt_used', 'driver_age'
]

# Split columns by type for preprocessing
numeric_cols = ['vehicle_speed', 'alcohol_level', 'vehicle_age', 'num_vehicles', 'driver_age']
categorical_cols = ['weather', 'road_surface', 'time_of_day', 'seatbelt_used']

print("âœ… Target and feature columns defined successfully!")

# ðŸ“˜ Part 5: Build the Linear Regression pipeline

# Create a numeric transformer (scales numeric values)
num_transformer = Pipeline(steps=[
    ('scaler', StandardScaler())
])

# Create a categorical transformer (encodes text data)
cat_transformer = Pipeline(steps=[
    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))
])

# Combine both transformers
preprocessor = ColumnTransformer(transformers=[
    ('num', num_transformer, numeric_cols),
    ('cat', cat_transformer, categorical_cols)
])

# Create the full pipeline: preprocessing + model
model_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('model', LinearRegression())
])

print("âœ… Model pipeline created successfully!")

# Replacement Part 5 â€” robust pipeline creation (use this cell)
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.linear_model import LinearRegression

# -- 1) Make sure numeric columns are numeric (coerce bad values to NaN)
for col in numeric_cols:
    df[col] = pd.to_numeric(df[col], errors='coerce')

# -- 2) Ensure categorical columns are strings (avoid lists/ints causing type errors)
for col in categorical_cols:
    df[col] = df[col].astype(str).fillna('Unknown')

# -- 3) Show dtypes so you can verify
print("Column dtypes after conversion:")
print(df[numeric_cols + categorical_cols].dtypes)
print("\nSample rows:")
print(df[numeric_cols + categorical_cols].head())

# -- 4) Fill any newly created NaNs in numeric columns (median)
df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())

# -- 5) Create OneHotEncoder with backward-compatible parameter
ohe_kwargs = {}
try:
    # sklearn >= 1.2 uses sparse_output
    OneHotEncoder(sparse_output=False)
    ohe_kwargs['sparse_output'] = False
except TypeError:
    # fallback for older sklearn versions
    ohe_kwargs['sparse'] = False

cat_transformer = Pipeline(steps=[
    ('onehot', OneHotEncoder(handle_unknown='ignore', **ohe_kwargs))
])

num_transformer = Pipeline(steps=[
    ('scaler', StandardScaler())
])

preprocessor = ColumnTransformer(transformers=[
    ('num', num_transformer, numeric_cols),
    ('cat', cat_transformer, categorical_cols)
], remainder='drop')

# -- 6) Final pipeline
model_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('regressor', LinearRegression())
])

print("\nâœ… Robust pipeline created. Ready to train.")

# ðŸ“˜ Part 6: Train and evaluate the Linear Regression model

# Train (fit) the model on the training data
model_pipeline.fit(X_train, y_train)

# Make predictions on the test data
y_pred = model_pipeline.predict(X_test)

# Evaluate model performance
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("âœ… Model trained successfully!")
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"RÂ² Score: {r2:.2f}")

# Optional: Compare actual vs predicted visually
plt.figure(figsize=(6, 4))
plt.scatter(y_test, y_pred, alpha=0.6)
plt.xlabel("Actual Severity")
plt.ylabel("Predicted Severity")
plt.title("Actual vs Predicted Accident Severity")
plt.grid(True)
plt.show()

# ðŸ“˜ Part 6 (fixed): Train and evaluate the Linear Regression model

# Make sure features and target are defined again (just in case)
X = df[features]
y = df[target]

# Split data again if necessary
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train (fit) the model
model_pipeline.fit(X_train, y_train)

# Predict on test set
y_pred = model_pipeline.predict(X_test)

# Evaluate performance
from sklearn.metrics import mean_squared_error, r2_score
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y

# ðŸ“˜ Part 6 (final fix): Train and evaluate the Linear Regression model

# Make sure features and target are defined
X = df[features]
y = df[target]

# Split data again to be safe
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Train (fit) the model
model_pipeline.fit(X_train, y_train)

# Predict on test data
y_pred = model_pipeline.predict(X_test)

# Evaluate performance
from sklearn.metrics import mean_squared_error, r2_score
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("âœ… Model trained and evaluated successfully!")
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"RÂ² Score: {r2:.2f}")

# --- Visualization ---
import matplotlib.pyplot as plt
plt.figure(figsize=(6, 4))
plt.scatter(y_test, y_pred, alpha=0.6, color='blue')
plt.xlabel("Actual Severity")
plt.ylabel("Predicted Severity")
plt.title("Actual vs Predicted Accident Severity")
plt.grid(True)
plt.show()

# @title
# ðŸ“˜ Part 7: Save and reload your trained model

# Save the trained model to a file
joblib.dump(model_pipeline, '/content/road_accident_model.pkl')
print("âœ… Model saved successfully as 'road_accident_model.pkl'!")

# To reload the model later without retraining:
loaded_model = joblib.load('/content/road_accident_model.pkl')

# Test the reloaded model on the test set
y_pred_loaded = loaded_model.predict(X_test)

# Confirm both models give the same performance
from sklearn.metrics import mean_squared_error, r2_score
mse_loaded = mean_squared_error(y_test, y_pred_loaded)
r2_loaded = r2_score(y_test, y_pred_loaded)

print(f"Reloaded Model - MSE: {mse_loaded:.2f}")
print(f"Reloaded Model - RÂ²: {r2_loaded:.2f}")